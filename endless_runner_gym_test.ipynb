{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endless Runner Q-table training\n",
    "\n",
    "Heavily inspired on the Q-table Colab notebook from Huggingface's DeepRL course: https://huggingface.co/learn/deep-rl-course/unit2/hands-on\n",
    "\n",
    "(Aqu√≠ dejo esto para que no se me olvide. Para correr el ambiente, primero se debe instalar el paquete de GameEnvs, para hacer esto lo que hago es irme a /GameEnvs y corro pip install -e .)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///D:/Repository/GameDevsCSF/RL-environments/GameEnvs\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: GameEnvs\n",
      "  Attempting uninstall: GameEnvs\n",
      "    Found existing installation: GameEnvs 0.0.1\n",
      "    Uninstalling GameEnvs-0.0.1:\n",
      "      Successfully uninstalled GameEnvs-0.0.1\n",
      "  Running setup.py develop for GameEnvs\n",
      "Successfully installed GameEnvs-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e GameEnvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the next cell, we'll kill the kernel to make sure the installed package is imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Restart the kernel after running this cell to make sure that the package is imported correctly.\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the next cell by stopping it, restarting the kernel and running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import GameEnvs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of distances in this particular environment goes from 50 (player_x - obstacle_width) to 800 (the set screen width)\n",
    "\n",
    "Binning with 76 leads to an array like this: \n",
    "```\n",
    "[ 50.  60.  70.  80.  90. 100. 110. 120. 130. 140. 150. 160. 170. 180.\n",
    " 190. 200. 210. 220. 230. 240. 250. 260. 270. 280. 290. 300. 310. 320.\n",
    " 330. 340. 350. 360. 370. 380. 390. 400. 410. 420. 430. 440. 450. 460.\n",
    " 470. 480. 490. 500. 510. 520. 530. 540. 550. 560. 570. 580. 590. 600.\n",
    " 610. 620. 630. 640. 650. 660. 670. 680. 690. 700. 710. 720. 730. 740.\n",
    " 750. 760. 770. 780. 790. 800.]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    }
   ],
   "source": [
    "bins = 76\n",
    "env = gym.make(\"EndlessRunner-v0\", obstacle_x_bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(3)\n",
      "Sample action: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Sample action:\", env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actions are: do nothing, jump or duck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Q-table\n",
    "Need to discretize the observations to make the Q-table. The solution seems to be to bin the observations, the question is how.\n",
    "\n",
    "We have the obstacle's x position, the obstacles y positon and the player's y positon.\n",
    "\n",
    "- Obstacle x: Goes from being at x = 800 to x = 50 (behind the player). The bin size could translate into \"how fast\" the agent reacts to having an obstacle in front of it.\n",
    "- Obstacle y: is either on the floor (0) or above the floor (1).\n",
    "- Player y: Is either standing (0), ducking (1), jumping (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Tuple(Discrete(2), Discrete(76))\n",
      "Sample observation: (1, 25)\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Sample observation:\", env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  3  actions in the action space.\n",
      "There are  152  observations in the observation space.\n"
     ]
    }
   ],
   "source": [
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" actions in the action space.\")\n",
    "\n",
    "observation_space = env.observation_space.spaces[0].n * env.observation_space.spaces[1].n \n",
    "print(\"There are \", observation_space, \" observations in the observation space.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_q_table(state_space, action_space):\n",
    "    q_table = np.zeros([state_space, action_space])\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtable shape: (76, 3)\n",
      "Qtable: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Qtable_runner = initialize_q_table(bins, action_space)\n",
    "print(\"Qtable shape:\", Qtable_runner.shape)\n",
    "print(\"Qtable:\", Qtable_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over\n",
      "Episode finished after 87 timesteps\n",
      "Game Over\n",
      "Episode finished after 87 timesteps\n",
      "Game Over\n",
      "Episode finished after 188 timesteps\n",
      "Game Over\n",
      "Episode finished after 87 timesteps\n",
      "Game Over\n",
      "Episode finished after 92 timesteps\n",
      "Game Over\n",
      "Episode finished after 96 timesteps\n",
      "Game Over\n",
      "Episode finished after 87 timesteps\n",
      "Game Over\n",
      "Episode finished after 87 timesteps\n",
      "Game Over\n",
      "Episode finished after 87 timesteps\n",
      "Game Over\n",
      "Episode finished after 87 timesteps\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    env.reset()\n",
    "    for t in range(10000):\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        if terminated:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-lab-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
