{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endless Runner Q-table training\n",
    "\n",
    "Heavily inspired on the Q-table Colab notebook from Huggingface's DeepRL course: https://huggingface.co/learn/deep-rl-course/unit2/hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import GameEnvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"EndlessRunner-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(3)\n",
      "Sample action: 2\n",
      "Observation space: Dict('obstacle_x': Box(50.0, 800.0, (1,), float32), 'obstacle_y': Box(266.66666, 300.0, (1,), float32), 'player_y': Box(300.0, 321.0, (1,), float32))\n",
      "Sample observation: OrderedDict({'obstacle_x': array([506.74197], dtype=float32), 'obstacle_y': array([268.97168], dtype=float32), 'player_y': array([314.36783], dtype=float32)})\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Sample action:\", env.action_space.sample())\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Sample observation:\", env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Q-table\n",
    "Need to discretize the observations to make the Q-table. The solution seems to be to bin the observations, the question is how.\n",
    "\n",
    "We have the obstacle's x position, the obstacles y positon and the player's y positon.\n",
    "\n",
    "Obstacle x: Goes from being at x = 800 to x = 50 (behind the player)\n",
    "Obstacle y: is either at the low (300) or high position (266.66666)\n",
    "Player y: goes from floor level (300) to max jump height (195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-lab-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
